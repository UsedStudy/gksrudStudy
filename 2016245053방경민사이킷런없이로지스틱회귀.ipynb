{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2016245053방경민사이킷런없이로지스틱회귀.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP7vQ44onXscMTmDnvzKYXq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gururur/gksrudStudy/blob/master/2016245053%EB%B0%A9%EA%B2%BD%EB%AF%BC%EC%82%AC%EC%9D%B4%ED%82%B7%EB%9F%B0%EC%97%86%EC%9D%B4%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%ED%9A%8C%EA%B7%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2bXWmor-y33"
      },
      "source": [
        "#과제1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3UeyCR_7QOX"
      },
      "source": [
        "데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzZCeeJsUwkk"
      },
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cysg7SMU88V"
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "X = iris[\"data\"][:, 3:]                   \n",
        "y = (iris[\"target\"] == 2).astype(np.int)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fXqrWaOU85V"
      },
      "source": [
        "X_with_bias = np.c_[np.ones([len(X),1]),X]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2MrjyFVU82m"
      },
      "source": [
        "np.random.seed(2042)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgCocrY-8GlH"
      },
      "source": [
        "데이터 분할 = 사이킷런의 train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNGvcW3ZU8zt"
      },
      "source": [
        "test_ratio = 0.2\n",
        "validation_ratio = 0.2\n",
        "total_size = len(X_with_bias)\n",
        "\n",
        "test_size = int(total_size * test_ratio)\n",
        "validation_size = int(total_size * validation_ratio)\n",
        "train_size = total_size - test_size - validation_size\n",
        "\n",
        "rnd_indices = np.random.permutation(total_size)\n",
        "\n",
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y[rnd_indices[train_size:-test_size]]\n",
        "\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USYmcpr1mj2Z"
      },
      "source": [
        "def to_one_hot(y):\n",
        "    n_classes = 2                # 클래스 수를 2로 고정시키면 로지스틱 함수와 같다.\n",
        "    m = len(y)                             \n",
        "    Y_one_hot = np.zeros((m, n_classes))    \n",
        "    Y_one_hot[np.arange(m), y] = 1          \n",
        "    return Y_one_hot\n",
        "\n",
        "Y_train_one_hot = to_one_hot(y_train)\n",
        "Y_valid_one_hot = to_one_hot(y_valid)\n",
        "Y_test_one_hot = to_one_hot(y_test)\n",
        "\n",
        "ytr=Y_train_one_hot[:,1]\n",
        "yva=Y_valid_one_hot\n",
        "yte=Y_test_one_hot\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-KnHiWr8LTe"
      },
      "source": [
        "로지스틱 회귀는 시그모이드 함수를 사용함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiT7rSI1YEGv"
      },
      "source": [
        "\n",
        "#SIGMOID FUNCTION\n",
        "def sigmoid(z):\n",
        "    y_head = 1 / (1 + np.exp(-z))\n",
        "    return y_head"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRyI3ScyfPV3"
      },
      "source": [
        "배치경사하강법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZ_YrAAdZ4P0"
      },
      "source": [
        "n_inputs = X_train.shape[1]           \n",
        "n_outputs = len(np.unique(y_train))   \n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzB9LxhfYl_n",
        "outputId": "78aab507-8c0b-481b-fa11-d4543208179c"
      },
      "source": [
        "eta = 0.01\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "\n",
        "for iteration in range(n_iterations):     \n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = sigmoid(logits)\n",
        "    \n",
        "    if iteration % 500 == 0:              \n",
        "        loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "        print(iteration, loss)\n",
        "    \n",
        "    error = Y_proba - Y_train_one_hot     \n",
        "    gradients = 1/m * X_train.T.dot(error)\n",
        "    \n",
        "    Theta = Theta - eta * gradients       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.6216585388989472\n",
            "500 0.5358155407854331\n",
            "1000 0.46868915858417054\n",
            "1500 0.4228110723139094\n",
            "2000 0.389997119276909\n",
            "2500 0.36532453055572167\n",
            "3000 0.34600634309210915\n",
            "3500 0.33038385603797926\n",
            "4000 0.3174181616594949\n",
            "4500 0.3064286658965357\n",
            "5000 0.2969519170535297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQkFK6lrbNmV",
        "outputId": "fbc713e7-5786-4268-ac82-855be16889ca"
      },
      "source": [
        "logits = X_valid.dot(Theta)              \n",
        "Y_proba = sigmoid(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)          \n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)  \n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxhRkJvwgFuH"
      },
      "source": [
        "규제를 더한 배치경사하강법"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyebjU6BbRpl",
        "outputId": "647d2a78-bbb9-4262-e8b0-27c93bfdd1a2"
      },
      "source": [
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1       \n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)  \n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = sigmoid(logits)\n",
        "    \n",
        "    if iteration % 500 == 0:\n",
        "         xentropy_loss =  -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "         l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "         loss = (xentropy_loss + alpha * l2_loss)    \n",
        "         print(iteration, loss)\n",
        "    \n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    l2_loss_gradients = np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]   \n",
        "    gradients = 1/m * X_train.T.dot(error) + l2_loss_gradients\n",
        "    \n",
        "    Theta = Theta - eta * gradients"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.7162610260856582\n",
            "500 0.5424422902989774\n",
            "1000 0.5489288755349917\n",
            "1500 0.549640024455795\n",
            "2000 0.5497072521674562\n",
            "2500 0.5497135348935831\n",
            "3000 0.5497141214229124\n",
            "3500 0.5497141761734805\n",
            "4000 0.5497141812842178\n",
            "4500 0.5497141817612832\n",
            "5000 0.5497141818058153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu_I7NcNbTbF",
        "outputId": "b8790834-b5fb-4a79-b7f1-783b5b07547c"
      },
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = sigmoid(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9YmAjiSgKzX"
      },
      "source": [
        "조기 종료 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3szxf7YCqrOw",
        "outputId": "3bad2a70-07a9-4813-cbe5-4d8b04354aab"
      },
      "source": [
        "eta = 0.1 \n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1            \n",
        "best_loss = np.infty   \n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)  \n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    \n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = sigmoid(logits)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
        "    Theta = Theta - eta * gradients\n",
        "\n",
        "    logits = X_valid.dot(Theta)\n",
        "    Y_proba = sigmoid(logits)\n",
        "    xentropy_loss = -np.mean(np.sum(Y_valid_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "    loss = (xentropy_loss + alpha * l2_loss)\n",
        "    \n",
        "\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss)\n",
        "        \n",
        "    \n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:                                      \n",
        "        print(iteration - 1, best_loss)        \n",
        "        print(iteration, loss, \"조기 종료!\")\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.6586122784654648\n",
            "0 0.6586122784654648\n",
            "1 0.6614977663257443 조기 종료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z407EP-_Y8xl",
        "outputId": "3fdb4dae-ad6f-4ad1-f1ba-f52e72c17d0f"
      },
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = sigmoid(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8MT2tJeqFEP"
      },
      "source": [
        "#과제2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx-t3prmJJVu"
      },
      "source": [
        "eta = 0.1 \n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1            \n",
        "best_loss = np.infty   \n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)  \n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    \n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = sigmoid(logits)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
        "    Theta = Theta - eta * gradients\n",
        "\n",
        "    logits = X_valid.dot(Theta)\n",
        "    Y_proba = sigmoid(logits)\n",
        "    xentropy_loss = -np.mean(np.sum(Y_valid_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "    loss = (xentropy_loss + alpha * l2_loss)\n",
        "    \n",
        "\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss)\n",
        "        \n",
        "    \n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:                                      \n",
        "        print(iteration - 1, best_loss)        \n",
        "        print(iteration, loss, \"조기 종료!\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Eqb_0cQIddW"
      },
      "source": [
        "다른 강의 과제도 많이 밀려서 시간이 나면 마저 하겠습니다.\n",
        "OvR 이론이 대충 1 = a + b + c 여서 a와 b를 구하면 c = 1 - a - b 인건 알겠습니다.  \n",
        "\n"
      ]
    }
  ]
}